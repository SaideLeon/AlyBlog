{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO6smyZiDDVV3SLDq7ZjxLf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaideLeon/AlyBlog/blob/main/Qwen3_TTS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Qwen3-TTS â€” Clonagem de Voz com Interface em PortuguÃªs\n",
        "#\n",
        "# Modelo: Qwen3-TTS-12Hz-1.7B-Base\n",
        "# FunÃ§Ã£o: Voice Clone (Clonagem de Voz)\n",
        "# ============================================\n",
        "\n",
        "# ============================================\n",
        "# CÃ‰LULA 1: InstalaÃ§Ã£o das dependÃªncias\n",
        "# ============================================\n",
        "!pip install -q qwen-tts flash-attn --no-build-isolation gradio soundfile\n",
        "\n",
        "# ============================================\n",
        "# CÃ‰LULA 2: ImportaÃ§Ã£o das bibliotecas\n",
        "# ============================================\n",
        "import torch\n",
        "import soundfile as sf\n",
        "import gradio as gr\n",
        "from qwen_tts import Qwen3TTSModel\n",
        "\n",
        "# ============================================\n",
        "# CÃ‰LULA 3: Carregamento do modelo de clonagem\n",
        "# ============================================\n",
        "print(\"Carregando modelo de clonagem de voz...\")\n",
        "model = Qwen3TTSModel.from_pretrained(\n",
        "    \"Qwen/Qwen3-TTS-12Hz-1.7B-Base\",\n",
        "    device_map=\"cuda:0\",\n",
        "    dtype=torch.bfloat16,\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        ")\n",
        "print(\"Modelo carregado com sucesso!\")\n",
        "\n",
        "# ============================================\n",
        "# CÃ‰LULA 4: FunÃ§Ã£o de clonagem de voz\n",
        "# ============================================\n",
        "def clonar_voz(\n",
        "    novo_texto,\n",
        "    idioma,\n",
        "    audio_referencia,\n",
        "    texto_referencia\n",
        "):\n",
        "    \"\"\"\n",
        "    Clona a voz a partir de um Ã¡udio de referÃªncia\n",
        "    \"\"\"\n",
        "\n",
        "    # ValidaÃ§Ãµes\n",
        "    if not novo_texto.strip():\n",
        "        return None, \"âŒ Insira o texto que serÃ¡ falado\"\n",
        "\n",
        "    if audio_referencia is None:\n",
        "        return None, \"âŒ Envie um Ã¡udio de referÃªncia\"\n",
        "\n",
        "    if not texto_referencia.strip():\n",
        "        return None, \"âŒ Informe o texto falado no Ã¡udio de referÃªncia\"\n",
        "\n",
        "    try:\n",
        "        # GeraÃ§Ã£o da voz clonada\n",
        "        wavs, sr = model.generate_voice_clone(\n",
        "            text=novo_texto,\n",
        "            language=idioma if idioma != \"Auto\" else \"Auto\",\n",
        "            ref_audio=audio_referencia,\n",
        "            ref_text=texto_referencia,\n",
        "        )\n",
        "\n",
        "        # Retorna tupla (array_audio, sample_rate)\n",
        "        return (sr, wavs[0]), \"âœ… Voz clonada com sucesso!\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return None, f\"âŒ Erro: {str(e)}\"\n",
        "\n",
        "# ============================================\n",
        "# CÃ‰LULA 5: Interface Gradio (100% em portuguÃªs)\n",
        "# ============================================\n",
        "with gr.Blocks(title=\"Clonagem de Voz â€” Qwen3-TTS\") as demo:\n",
        "    gr.Markdown(\"# ğŸ™ï¸ Clonagem de Voz com IA (Qwen3-TTS)\")\n",
        "    gr.Markdown(\n",
        "        \"Clone uma voz real a partir de um Ã¡udio curto e gere novas falas com alta fidelidade.\"\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            # Texto que serÃ¡ falado pela voz clonada\n",
        "            novo_texto = gr.Textbox(\n",
        "                label=\"ğŸ“ Texto a ser falado\",\n",
        "                placeholder=\"Digite aqui o novo texto que a voz clonada irÃ¡ falar...\",\n",
        "                lines=4\n",
        "            )\n",
        "\n",
        "            # Idioma\n",
        "            idioma = gr.Dropdown(\n",
        "                choices=[\n",
        "                    \"Auto\", \"Chinese\", \"English\", \"Japanese\", \"Korean\",\n",
        "                    \"German\", \"French\", \"Russian\", \"Portuguese\", \"Spanish\", \"Italian\"\n",
        "                ],\n",
        "                value=\"Auto\",\n",
        "                label=\"ğŸŒ Idioma\"\n",
        "            )\n",
        "\n",
        "            gr.Markdown(\"### ğŸ§ Ãudio de referÃªncia (voz original)\")\n",
        "\n",
        "            # Upload do Ã¡udio de referÃªncia\n",
        "            audio_referencia = gr.Audio(\n",
        "                label=\"Ãudio de referÃªncia\",\n",
        "                type=\"filepath\"\n",
        "            )\n",
        "\n",
        "            # Texto falado no Ã¡udio de referÃªncia\n",
        "            texto_referencia = gr.Textbox(\n",
        "                label=\"ğŸ“„ Texto falado no Ã¡udio\",\n",
        "                placeholder=\"Digite exatamente o que Ã© falado no Ã¡udio enviado\",\n",
        "                lines=3\n",
        "            )\n",
        "\n",
        "            # BotÃ£o\n",
        "            gerar_btn = gr.Button(\n",
        "                \"ğŸ¤ Clonar voz e gerar Ã¡udio\",\n",
        "                variant=\"primary\",\n",
        "                size=\"lg\"\n",
        "            )\n",
        "\n",
        "        with gr.Column():\n",
        "            audio_saida = gr.Audio(\n",
        "                label=\"ğŸ”Š Ãudio gerado\",\n",
        "                type=\"numpy\"\n",
        "            )\n",
        "            status = gr.Textbox(\n",
        "                label=\"Status\",\n",
        "                lines=2\n",
        "            )\n",
        "\n",
        "            # AÃ§Ã£o do botÃ£o\n",
        "            gerar_btn.click(\n",
        "                fn=clonar_voz,\n",
        "                inputs=[novo_texto, idioma, audio_referencia, texto_referencia],\n",
        "                outputs=[audio_saida, status]\n",
        "            )\n",
        "\n",
        "# ============================================\n",
        "# InicializaÃ§Ã£o da aplicaÃ§Ã£o\n",
        "# ============================================\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "87907f4a42f647f5840ddb200dec835f",
            "858a6572ce1d48739921453ca6ee5384",
            "8379f84c4cf24a10a876f1481fe92c36",
            "c83b7b8f5dc949eab34889899eace821",
            "ffe9bf38d1e84d9db20a74f9939d7344",
            "5e11a7c4c3b043348d214e7bddc7bb9f",
            "6569a696243b4002b222db62da7599f7",
            "244e643ac6374afca213bafb1a397d74",
            "9fab6768d1b146eeb075bffe252e6336",
            "3c28f64012584e02b479031984f9829d",
            "24846a20f3d14aa38a7d617f85d51b09",
            "c3fdfba49fbd48d2845a5060ffff84b5"
          ]
        },
        "id": "Sqr2y_MVF1MK",
        "outputId": "6ebf35a2-b4d3-455d-ff40-c21675ca1a6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m113.3/113.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sox (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:sox:SoX could not be found!\n",
            "\n",
            "    If you do not have SoX, proceed here:\n",
            "     - - - http://sox.sourceforge.net/ - - -\n",
            "\n",
            "    If you do (or think that you should) have SoX, double-check your\n",
            "    path variables.\n",
            "    \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Carregando modelo de clonagem de voz...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87907f4a42f647f5840ddb200dec835f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "858a6572ce1d48739921453ca6ee5384",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8379f84c4cf24a10a876f1481fe92c36",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/245 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c83b7b8f5dc949eab34889899eace821",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ffe9bf38d1e84d9db20a74f9939d7344",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e11a7c4c3b043348d214e7bddc7bb9f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6569a696243b4002b222db62da7599f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "speech_tokenizer/model.safetensors:   0%|          | 0.00/682M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "244e643ac6374afca213bafb1a397d74",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "configuration.json:   0%|          | 0.00/76.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9fab6768d1b146eeb075bffe252e6336",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/127 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c28f64012584e02b479031984f9829d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24846a20f3d14aa38a7d617f85d51b09",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3fdfba49fbd48d2845a5060ffff84b5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo carregado com sucesso!\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://65f582102572b00ee8.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://65f582102572b00ee8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARNING] Min value of input waveform signal is -1.1017061471939087\n",
            "[WARNING] Max value of input waveform signal is 1.105940341949463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/processing_utils.py:688: UserWarning: Trying to convert audio automatically from float32 to 16-bit int format.\n",
            "  warnings.warn(warning.format(data.dtype))\n",
            "Setting `pad_token_id` to `eos_token_id`:2150 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WARNING] Min value of input waveform signal is -1.1017061471939087\n",
            "[WARNING] Max value of input waveform signal is 1.105940341949463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/processing_utils.py:688: UserWarning: Trying to convert audio automatically from float32 to 16-bit int format.\n",
            "  warnings.warn(warning.format(data.dtype))\n"
          ]
        }
      ]
    }
  ]
}